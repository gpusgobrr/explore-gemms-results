
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CUDA GEMM Benchmark Results</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
        }

        .container {
            max-width: 1400px;
            margin: 0 auto;
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 60px rgba(0,0,0,0.3);
            overflow: hidden;
        }

        header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 40px;
            text-align: center;
        }

        h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
        }

        .subtitle {
            font-size: 1.1em;
            opacity: 0.9;
        }

        .info-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            padding: 30px;
            background: #f8f9fa;
            border-bottom: 3px solid #e9ecef;
        }

        .info-card {
            background: white;
            padding: 20px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }

        .info-card h3 {
            color: #667eea;
            margin-bottom: 10px;
            font-size: 0.9em;
            text-transform: uppercase;
            letter-spacing: 1px;
        }

        .info-card p {
            color: #333;
            font-size: 1.3em;
            font-weight: bold;
        }

        .chart-container {
            padding: 30px;
        }

        .chart-container iframe {
            width: 100%;
            height: 950px;
            border: none;
            border-radius: 10px;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin: 30px;
            max-width: calc(100% - 60px);
        }

        th, td {
            padding: 15px;
            text-align: left;
            border-bottom: 1px solid #e9ecef;
        }

        th {
            background: #667eea;
            color: white;
            font-weight: 600;
            text-transform: uppercase;
            font-size: 0.85em;
            letter-spacing: 1px;
        }

        tr:hover {
            background: #f8f9fa;
        }

        .kernel-badge {
            display: inline-block;
            padding: 5px 12px;
            border-radius: 20px;
            font-size: 0.85em;
            font-weight: 600;
        }

        .badge-pytorch {
            background: #e3f2fd;
            color: #1976d2;
        }

        .badge-pytorch-jit {
            background: #f3e5f5;
            color: #7b1fa2;
        }

        .badge-naive {
            background: #ffebee;
            color: #c62828;
        }

        .badge-coalesced {
            background: #e8f5e9;
            color: #2e7d32;
        }

        .badge-shared {
            background: #f3e5f5;
            color: #7b1fa2;
        }

        .badge-blocktiling {
            background: #fff3e0;
            color: #e65100;
        }

        .badge-blocktiling2d {
            background: #e0f7fa;
            color: #006064;
        }

        .badge-vectorize {
            background: #fce4ec;
            color: #c2185b;
        }

        .badge-warptiling {
            background: #fff9c4;
            color: #f57f17;
        }

        .badge-tensorcore {
            background: #e0f2f1;
            color: #00695c;
        }

        .badge-cutlass {
            background: #ffe0b2;
            color: #e65100;
        }

        .speedup {
            font-weight: bold;
        }

        .speedup.faster {
            color: #2e7d32;
        }

        .speedup.slower {
            color: #c62828;
        }

        footer {
            text-align: center;
            padding: 20px;
            background: #f8f9fa;
            color: #666;
            font-size: 0.9em;
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>üöÄ CUDA GEMM Kernel Benchmarks (BFP16)</h1>
            <p class="subtitle">Performance Comparison: PyTorch vs Custom CUDA Kernels</p>
        </header>

        <div class="info-grid">
            <div class="info-card">
                <h3>üñ•Ô∏è GPU</h3>
                <p>NVIDIA H100 80GB HBM3</p>
            </div>
            <div class="info-card">
                <h3>üìä Data Type</h3>
                <p>BFP16</p>
            </div>
            <div class="info-card">
                <h3>‚è∞ Timestamp</h3>
                <p>2025-12-30 10:52:32</p>
            </div>
            <div class="info-card">
                <h3>üî¢ Test Sizes</h3>
                <p>12 configurations</p>
            </div>
            <div class="info-card">
                <h3>‚ö° Kernels Tested</h3>
                <p>2 kernels</p>
            </div>
        </div>

        <div class="chart-container">
            <iframe src="benchmark_results.html"></iframe>
        </div>

        <h2 style="padding: 30px 30px 0 30px; color: #333;">üìä Detailed Results</h2>
        <table>
            <thead>
                <tr>
                    <th>Matrix Size</th>
                    <th>Kernel</th>
                    <th>Avg Time (ms)</th>
                    <th>TFLOP16s</th>
                    <th>Bandwidth (GB/s)</th>
                    <th>Speedup</th>
                </tr>
            </thead>
            <tbody>

                <tr>
                    <td><strong>64√ó64</strong></td>
                    <td><span class="kernel-badge badge-pytorch">PyTorch</span></td>
                    <td>0.0240</td>
                    <td><strong>0.02</strong></td>
                    <td>1.02</td>
                    <td><span class="speedup ">baseline</span></td>
                </tr>

                <tr>
                    <td><strong>64√ó64</strong></td>
                    <td><span class="kernel-badge badge-cutlass">CUTLASS Hopper TMA Pingpong Const</span></td>
                    <td>0.0229</td>
                    <td><strong>0.02</strong></td>
                    <td>1.07</td>
                    <td><span class="speedup faster">1.05√ó</span></td>
                </tr>

                <tr>
                    <td><strong>96√ó96</strong></td>
                    <td><span class="kernel-badge badge-pytorch">PyTorch</span></td>
                    <td>0.0616</td>
                    <td><strong>0.03</strong></td>
                    <td>0.90</td>
                    <td><span class="speedup ">baseline</span></td>
                </tr>

                <tr>
                    <td><strong>96√ó96</strong></td>
                    <td><span class="kernel-badge badge-cutlass">CUTLASS Hopper TMA Pingpong Const</span></td>
                    <td>0.0418</td>
                    <td><strong>0.04</strong></td>
                    <td>1.32</td>
                    <td><span class="speedup faster">1.47√ó</span></td>
                </tr>

                <tr>
                    <td><strong>128√ó128</strong></td>
                    <td><span class="kernel-badge badge-pytorch">PyTorch</span></td>
                    <td>0.0605</td>
                    <td><strong>0.07</strong></td>
                    <td>1.62</td>
                    <td><span class="speedup ">baseline</span></td>
                </tr>

                <tr>
                    <td><strong>128√ó128</strong></td>
                    <td><span class="kernel-badge badge-cutlass">CUTLASS Hopper TMA Pingpong Const</span></td>
                    <td>0.0348</td>
                    <td><strong>0.12</strong></td>
                    <td>2.82</td>
                    <td><span class="speedup faster">1.74√ó</span></td>
                </tr>

                <tr>
                    <td><strong>256√ó256</strong></td>
                    <td><span class="kernel-badge badge-pytorch">PyTorch</span></td>
                    <td>0.0256</td>
                    <td><strong>1.31</strong></td>
                    <td>15.37</td>
                    <td><span class="speedup ">baseline</span></td>
                </tr>

                <tr>
                    <td><strong>256√ó256</strong></td>
                    <td><span class="kernel-badge badge-cutlass">CUTLASS Hopper TMA Pingpong Const</span></td>
                    <td>0.0246</td>
                    <td><strong>1.37</strong></td>
                    <td>16.00</td>
                    <td><span class="speedup faster">1.04√ó</span></td>
                </tr>

                <tr>
                    <td><strong>512√ó512</strong></td>
                    <td><span class="kernel-badge badge-pytorch">PyTorch</span></td>
                    <td>0.0261</td>
                    <td><strong>10.30</strong></td>
                    <td>60.35</td>
                    <td><span class="speedup ">baseline</span></td>
                </tr>

                <tr>
                    <td><strong>512√ó512</strong></td>
                    <td><span class="kernel-badge badge-cutlass">CUTLASS Hopper TMA Pingpong Const</span></td>
                    <td>0.0270</td>
                    <td><strong>9.93</strong></td>
                    <td>58.20</td>
                    <td><span class="speedup slower">0.96√ó</span></td>
                </tr>

                <tr>
                    <td><strong>768√ó768</strong></td>
                    <td><span class="kernel-badge badge-pytorch">PyTorch</span></td>
                    <td>0.0260</td>
                    <td><strong>34.87</strong></td>
                    <td>136.20</td>
                    <td><span class="speedup ">baseline</span></td>
                </tr>

                <tr>
                    <td><strong>768√ó768</strong></td>
                    <td><span class="kernel-badge badge-cutlass">CUTLASS Hopper TMA Pingpong Const</span></td>
                    <td>0.0300</td>
                    <td><strong>30.22</strong></td>
                    <td>118.03</td>
                    <td><span class="speedup slower">0.87√ó</span></td>
                </tr>

                <tr>
                    <td><strong>1024√ó1024</strong></td>
                    <td><span class="kernel-badge badge-pytorch">PyTorch</span></td>
                    <td>0.0261</td>
                    <td><strong>82.24</strong></td>
                    <td>240.94</td>
                    <td><span class="speedup ">baseline</span></td>
                </tr>

                <tr>
                    <td><strong>1024√ó1024</strong></td>
                    <td><span class="kernel-badge badge-cutlass">CUTLASS Hopper TMA Pingpong Const</span></td>
                    <td>0.0330</td>
                    <td><strong>65.15</strong></td>
                    <td>190.88</td>
                    <td><span class="speedup slower">0.79√ó</span></td>
                </tr>

                <tr>
                    <td><strong>1536√ó1536</strong></td>
                    <td><span class="kernel-badge badge-pytorch">PyTorch</span></td>
                    <td>0.0298</td>
                    <td><strong>243.54</strong></td>
                    <td>475.66</td>
                    <td><span class="speedup ">baseline</span></td>
                </tr>

                <tr>
                    <td><strong>1536√ó1536</strong></td>
                    <td><span class="kernel-badge badge-cutlass">CUTLASS Hopper TMA Pingpong Const</span></td>
                    <td>0.0545</td>
                    <td><strong>133.00</strong></td>
                    <td>259.76</td>
                    <td><span class="speedup slower">0.55√ó</span></td>
                </tr>

                <tr>
                    <td><strong>2048√ó2048</strong></td>
                    <td><span class="kernel-badge badge-pytorch">PyTorch</span></td>
                    <td>0.0423</td>
                    <td><strong>405.80</strong></td>
                    <td>594.43</td>
                    <td><span class="speedup ">baseline</span></td>
                </tr>

                <tr>
                    <td><strong>2048√ó2048</strong></td>
                    <td><span class="kernel-badge badge-cutlass">CUTLASS Hopper TMA Pingpong Const</span></td>
                    <td>0.0655</td>
                    <td><strong>262.21</strong></td>
                    <td>384.09</td>
                    <td><span class="speedup slower">0.65√ó</span></td>
                </tr>

                <tr>
                    <td><strong>3072√ó3072</strong></td>
                    <td><span class="kernel-badge badge-pytorch">PyTorch</span></td>
                    <td>0.0931</td>
                    <td><strong>622.66</strong></td>
                    <td>608.07</td>
                    <td><span class="speedup ">baseline</span></td>
                </tr>

                <tr>
                    <td><strong>3072√ó3072</strong></td>
                    <td><span class="kernel-badge badge-cutlass">CUTLASS Hopper TMA Pingpong Const</span></td>
                    <td>0.1762</td>
                    <td><strong>329.08</strong></td>
                    <td>321.37</td>
                    <td><span class="speedup slower">0.53√ó</span></td>
                </tr>

                <tr>
                    <td><strong>4096√ó4096</strong></td>
                    <td><span class="kernel-badge badge-pytorch">PyTorch</span></td>
                    <td>0.1910</td>
                    <td><strong>719.61</strong></td>
                    <td>527.06</td>
                    <td><span class="speedup ">baseline</span></td>
                </tr>

                <tr>
                    <td><strong>4096√ó4096</strong></td>
                    <td><span class="kernel-badge badge-cutlass">CUTLASS Hopper TMA Pingpong Const</span></td>
                    <td>0.3696</td>
                    <td><strong>371.81</strong></td>
                    <td>272.32</td>
                    <td><span class="speedup slower">0.52√ó</span></td>
                </tr>

                <tr>
                    <td><strong>8192√ó8192</strong></td>
                    <td><span class="kernel-badge badge-pytorch">PyTorch</span></td>
                    <td>1.5816</td>
                    <td><strong>695.17</strong></td>
                    <td>254.58</td>
                    <td><span class="speedup ">baseline</span></td>
                </tr>

                <tr>
                    <td><strong>8192√ó8192</strong></td>
                    <td><span class="kernel-badge badge-cutlass">CUTLASS Hopper TMA Pingpong Const</span></td>
                    <td>2.7103</td>
                    <td><strong>405.68</strong></td>
                    <td>148.56</td>
                    <td><span class="speedup slower">0.58√ó</span></td>
                </tr>

            </tbody>
        </table>

        <footer>
            <p>Generated by CUDA GEMM Benchmark Suite ‚Ä¢ Powered by PyTorch & Plotly</p>
        </footer>
    </div>
</body>
</html>
